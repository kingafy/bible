{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "3.NER_with_BERT.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADl6qtQGyC_6",
        "colab_type": "text"
      },
      "source": [
        "# NER with BERT in Spark NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJXZ9O_uyC_9",
        "colab_type": "code",
        "colab": {},
        "outputId": "684a2ab0-a802-48a8-cf9c-b4ea7da27dde"
      },
      "source": [
        "!python -V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imq4L414yDAE",
        "colab_type": "text"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ULcdCdIyDAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.5.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_rMAwMyDAK",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries and download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB19-dqfyDAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwkmKALKyDAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = sparknlp.start()\n",
        "#spark = sparknlp.start(gpu=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy59-XMMyDAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dah-H8tyDAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start(gpu=False):\n",
        "    builder = SparkSession.builder \\\n",
        "        .appName(\"Spark NLP\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .config(\"spark.driver.memory\", \"8G\") \\\n",
        "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\\\n",
        "        .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\n",
        "    if gpu:\n",
        "        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp-gpu_2.11:2.5.1\")\n",
        "    else:\n",
        "        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.1\")\n",
        "\n",
        "    return builder.getOrCreate()\n",
        "\n",
        "  \n",
        "spark = start(gpu=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4UsTCDuyDAc",
        "colab_type": "code",
        "colab": {},
        "outputId": "6eb41997-dbab-4055-a212-1336eda7d20f"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "urlretrieve('https://github.com/JohnSnowLabs/spark-nlp/raw/master/src/test/resources/conll2003/eng.train',\n",
        "           'eng.train')\n",
        "\n",
        "urlretrieve('https://github.com/JohnSnowLabs/spark-nlp/raw/master/src/test/resources/conll2003/eng.testa',\n",
        "           'eng.testa')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('eng.testa', <http.client.HTTPMessage at 0x1a1a1318d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Od9CXJnyDAi",
        "colab_type": "code",
        "colab": {},
        "outputId": "4b9e6f91-11cc-4e21-d0b5-bfe98b787b85"
      },
      "source": [
        "with open(\"eng.train\") as f:\n",
        "    c=f.read()\n",
        "\n",
        "print (c[:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP I-NP I-ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP I-MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP I-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP I-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP I-NP I-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP I-ORG\n",
            "Commission NNP I-NP I-ORG\n",
            "said VBD I-VP O\n",
            "on IN I-PP O\n",
            "Thursday NNP I-NP O\n",
            "it PRP B-NP O\n",
            "disagreed VBD I-VP O\n",
            "with IN I-PP O\n",
            "German JJ I-NP I-MISC\n",
            "advice NN I-NP O\n",
            "to TO I-PP O\n",
            "consumers NNS I-NP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7dOJTn2yDAl",
        "colab_type": "text"
      },
      "source": [
        "## Building NER pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLLubSIryDAn",
        "colab_type": "code",
        "colab": {},
        "outputId": "84c1c35c-40c6-43d0-ad6f-63563b7e9d7c"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "training_data.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
            "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtpqKTIoyDAt",
        "colab_type": "code",
        "colab": {},
        "outputId": "beba21a4-4ab3-4f7b-d809-54d44bf7912b"
      },
      "source": [
        "training_data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14041"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTw54BSWyDAx",
        "colab_type": "text"
      },
      "source": [
        "### Loading Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kosFcGLEyDAy",
        "colab_type": "text"
      },
      "source": [
        "In Spark NLP, we have four pre-trained variants of BERT: bert_base_uncased , bert_base_cased , bert_large_uncased , bert_large_cased . Which one to use depends on your use case, train set, and the complexity of the task you are trying to model.\n",
        "\n",
        "In the code snippet above, we basically load the bert_base_cased version from Spark NLP public resources and point thesentenceand token columns in   setInputCols(). In short, BertEmbeddings() annotator will take sentence and token columns and populate Bert embeddings in bert column. In general, each word is translated to a 768-dimensional vector. The parametersetPoolingLayer() can be set to 0 as the first layer and fastest, -1 as the last layer and -2 as the second-to-last-hidden layer.\n",
        "\n",
        "As explained by the authors of official BERT paper, different BERT layers capture different information. The last layer is too closed to the target functions (i.e. masked language model and next sentence prediction) during pre-training, therefore it may be biased to those targets. If you want to use the last hidden layer anyway, please feel free to set pooling_layer=-1. Intuitively, pooling_layer=-1 is close to the training output, so it may be biased to the training targets. If you don't fine-tune the model, then this could lead to a bad representation. That said, it is a matter of trade-off between model accuracy and computational resources you have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPoia4XayDAz",
        "colab_type": "code",
        "colab": {},
        "outputId": "4e4c3877-f3b6-4f18-e58c-06b0302849a6"
      },
      "source": [
        "bert_annotator = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        " .setOutputCol(\"bert\")\\\n",
        " .setCaseSensitive(False)\\\n",
        " .setPoolingLayer(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.2 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVDeDSmkyDA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BertEmbeddings.load(\"local/path/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28rDWIpXyDA7",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb247495-f75d-4daa-de24-24313e167d65"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "\n",
        "test_data = bert_annotator.transform(test_data)\n",
        "\n",
        "test_data.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|                bert|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y33aQ3AyDA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_data.limit(1000).write.parquet(\"test_withEmbeds.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayzE-2oTyDBD",
        "colab_type": "code",
        "colab": {},
        "outputId": "25c4d131-8930-4792-f958-e502cab59121"
      },
      "source": [
        "test_data.select(\"bert.result\",\"bert.embeddings\",'label.result').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|              result|          embeddings|              result|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|[cricket, -, leic...|[[-0.1976323, -0....|[O, O, B-ORG, O, ...|\n",
            "|[london, 1996-08-30]|[[0.60744655, 0.2...|          [B-LOC, O]|\n",
            "|[west, indian, al...|[[-0.77769196, -0...|[B-MISC, I-MISC, ...|\n",
            "|[their, stay, on,...|[[-1.0986965, 0.9...|[O, O, O, O, O, O...|\n",
            "|[after, bowling, ...|[[-1.1295222, 0.4...|[O, O, B-ORG, O, ...|\n",
            "|[trailing, by, 21...|[[-1.763109, 0.64...|[O, O, O, O, B-OR...|\n",
            "|[essex, ,, howeve...|[[-0.7097074, -0....|[B-ORG, O, O, O, ...|\n",
            "|[hussain, ,, cons...|[[-0.18262176, 0....|[B-PER, O, O, O, ...|\n",
            "|[by, the, close, ...|[[-0.44396043, 0....|[O, O, O, B-ORG, ...|\n",
            "|[at, the, oval, ,...|[[-1.0189406, -0....|[O, O, B-LOC, O, ...|\n",
            "|[he, was, well, b...|[[-0.48848447, 0....|[O, O, O, O, O, B...|\n",
            "|[derbyshire, kept...|[[-0.08332734, -1...|[B-ORG, O, O, O, ...|\n",
            "|[australian, tom,...|[[0.20087296, 0.3...|[B-MISC, B-PER, I...|\n",
            "|[after, the, frus...|[[-1.1295222, 0.4...|[O, O, O, O, O, O...|\n",
            "|[they, were, held...|[[-1.2368866, 0.7...|[O, O, O, O, O, O...|\n",
            "|[by, stumps, kent...|[[-0.44396043, 0....|[O, O, B-ORG, O, ...|\n",
            "|[cricket, -, engl...|[[-0.1976323, -0....|[O, O, B-MISC, I-...|\n",
            "|[london, 1996-08-30]|[[0.60744655, 0.2...|          [B-LOC, O]|\n",
            "|[result, and, clo...|[[-1.3634797, -0....|[O, O, O, O, O, O...|\n",
            "|[leicester, :, le...|[[-0.21664326, 0....|[B-LOC, O, B-ORG,...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WThyIRNyDBH",
        "colab_type": "code",
        "colab": {},
        "outputId": "78f2cfb4-7ffc-4a81-d435-c880ee2aa115"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "emb_vector = np.array(test_data.select(\"bert.embeddings\").take(1))\n",
        "\n",
        "emb_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-0.1976323 , -0.42026019,  0.55059767, ...,  0.43232313,\n",
              "           0.08174106,  0.20429248],\n",
              "         [-0.95179886,  0.40518612, -0.18066669, ..., -0.56889868,\n",
              "           0.60068387,  0.0411097 ],\n",
              "         [-0.02262329,  0.5078364 ,  0.12273782, ..., -1.2903105 ,\n",
              "          -0.2035525 ,  0.46557245],\n",
              "         ...,\n",
              "         [ 0.05775764, -0.63264298, -0.66510761, ..., -0.70176458,\n",
              "           0.57686883, -0.59081137],\n",
              "         [ 0.26866663, -1.05502069, -0.19403641, ...,  0.30519044,\n",
              "           1.04685092,  0.74213707],\n",
              "         [-0.32736883,  0.54801679,  1.04293954, ...,  0.25098351,\n",
              "           0.55407429,  0.26589558]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azgJODBXyDBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nerTagger = NerDLApproach()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        "  .setLabelColumn(\"label\")\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setMaxEpochs(1)\\\n",
        "  .setLr(0.001)\\\n",
        "  .setPo(0.005)\\\n",
        "  .setBatchSize(8)\\\n",
        "  .setRandomSeed(0)\\\n",
        "  .setVerbose(1)\\\n",
        "  .setValidationSplit(0.2)\\\n",
        "  .setEvaluationLogExtended(True) \\\n",
        "  .setEnableOutputLogs(True)\\\n",
        "  .setIncludeConfidence(True)\\\n",
        "  .setTestDataset(\"test_withEmbeds.parquet\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    bert_annotator,\n",
        "    nerTagger\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-RlwoiJyDBQ",
        "colab_type": "text"
      },
      "source": [
        "You can also set learning rate ( setLr ), learning rate decay coefficient ( setPo ), setBatchSize and setDropout rate. Please see the official repo for the entire list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTsHdQaTyDBR",
        "colab_type": "code",
        "colab": {},
        "outputId": "537fb0d4-98b1-4552-a936-3cff1d1b4b12"
      },
      "source": [
        "%%time\n",
        "\n",
        "ner_model = pipeline.fit(training_data.limit(1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26.3 ms, sys: 15.1 ms, total: 41.4 ms\n",
            "Wall time: 44.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AUN9RBFyDBV",
        "colab_type": "code",
        "colab": {},
        "outputId": "c03c7edc-1919-4b7d-dcff-6577af773728"
      },
      "source": [
        "ner_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PipelineModel_cebcb55e7e77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DesFiy3nyDBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on COLAB, it takes 30 min to train entire trainset (conll2003) for 10 epochs on GPU with layer = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CeMbPESyDBd",
        "colab_type": "code",
        "colab": {},
        "outputId": "c91ac5b8-293b-40a7-ac65-ee0b9f7bcb6d"
      },
      "source": [
        "predictions = ner_model.transform(test_data)\n",
        "predictions.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|                bert|                 ner|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbPwEyCyDBh",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7fe143b-babc-4486-c82a-a7f54ff9b34d"
      },
      "source": [
        "predictions.select('token.result','label.result','ner.result').show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                  result|                                  result|                                  result|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|[CRICKET, -, LEICESTERSHIRE, TAKE, OV...|   [O, O, I-ORG, O, O, O, O, O, O, O, O]|   [O, O, I-PER, O, O, O, O, O, O, O, O]|\n",
            "|                    [LONDON, 1996-08-30]|                              [I-LOC, O]|                              [I-LOC, O]|\n",
            "|[West, Indian, all-rounder, Phil, Sim...|[I-MISC, I-MISC, O, I-PER, I-PER, O, ...|[I-LOC, O, O, I-ORG, I-ORG, O, O, O, ...|\n",
            "|[Their, stay, on, top, ,, though, ,, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[After, bowling, Somerset, out, for, ...|[O, O, I-ORG, O, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[Trailing, by, 213, ,, Somerset, got,...|[O, O, O, O, I-ORG, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[Essex, ,, however, ,, look, certain,...|[I-ORG, O, O, O, O, O, O, O, O, O, O,...|[I-PER, O, O, O, O, O, O, O, O, O, O,...|\n",
            "|[Hussain, ,, considered, surplus, to,...|[I-PER, O, O, O, O, I-LOC, O, O, O, O...|[I-PER, O, O, O, O, I-PER, O, O, O, O...|\n",
            "|[By, the, close, Yorkshire, had, turn...|[O, O, O, I-ORG, O, O, O, O, O, O, O,...|[O, O, O, I-LOC, O, O, O, O, O, O, O,...|\n",
            "|[At, the, Oval, ,, Surrey, captain, C...|[O, O, I-LOC, O, I-ORG, O, I-PER, I-P...|[O, O, I-PER, O, I-PER, O, I-PER, I-P...|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqsSMIf2yDBk",
        "colab_type": "code",
        "colab": {},
        "outputId": "1526e24a-53c2-4125-b744-45aa2291db1f"
      },
      "source": [
        "predictions.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- pos: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- label: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- bert: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- ner: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGSUSD-yDBo",
        "colab_type": "code",
        "colab": {},
        "outputId": "8e03a17a-efdb-4b3e-9c93-027ca3dbaf1c"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|I-ORG       |I-PER     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |I-LOC       |I-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |I-MISC      |I-LOC     |\n",
            "|Indian        |I-MISC      |O         |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |I-PER       |I-ORG     |\n",
            "|Simmons       |I-PER       |I-ORG     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxCyfdlPyDBt",
        "colab_type": "text"
      },
      "source": [
        "### Loading from local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYznQdldyDBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the one trained 10 epochs on GPU with entire train set\n",
        "\n",
        "loaded_ner_model = NerDLModel.load(\"NER_bert_20200226\")\\\n",
        " .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        " .setOutputCol(\"ner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdk5EX-YyDBx",
        "colab_type": "code",
        "colab": {},
        "outputId": "35eb90d9-5a1b-4e97-e385-1aeac2107d8b"
      },
      "source": [
        "predictions_loaded = loaded_ner_model.transform(test_data)\n",
        "\n",
        "predictions_loaded.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(30, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|I-ORG       |B-PER     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |I-LOC       |B-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |I-MISC      |B-MISC    |\n",
            "|Indian        |I-MISC      |I-MISC    |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |I-PER       |B-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "|for           |O           |O         |\n",
            "|38            |O           |O         |\n",
            "|on            |O           |O         |\n",
            "|Friday        |O           |O         |\n",
            "|as            |O           |O         |\n",
            "|Leicestershire|I-ORG       |B-ORG     |\n",
            "|beat          |O           |O         |\n",
            "|Somerset      |I-ORG       |O         |\n",
            "|by            |O           |O         |\n",
            "|an            |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 30 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHM-to65yDB0",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d7dd2f7-70ff-4f78-9b03-d9016c97c659"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = predictions_loaded.select('token.result','label.result','ner.result').toPandas()\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>result</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>[CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, T...</td>\n",
              "      <td>[O, O, I-ORG, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, B-PER, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>[LONDON, 1996-08-30]</td>\n",
              "      <td>[I-LOC, O]</td>\n",
              "      <td>[B-LOC, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>[West, Indian, all-rounder, Phil, Simmons, too...</td>\n",
              "      <td>[I-MISC, I-MISC, O, I-PER, I-PER, O, O, O, O, ...</td>\n",
              "      <td>[B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>[Their, stay, on, top, ,, though, ,, may, be, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, I-ORG,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>[After, bowling, Somerset, out, for, 83, on, t...</td>\n",
              "      <td>[O, O, I-ORG, O, O, O, O, O, O, O, O, I-LOC, I...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3245</td>\n",
              "      <td>[But, the, prices, may, move, in, a, close, ra...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3246</td>\n",
              "      <td>[Brokers, said, blue, chips, like, IDLC, ,, Ba...</td>\n",
              "      <td>[O, O, O, O, O, I-ORG, O, I-ORG, I-ORG, O, I-O...</td>\n",
              "      <td>[O, O, O, O, O, B-ORG, O, B-LOC, O, O, B-PER, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3247</td>\n",
              "      <td>[They, said, there, was, still, demand, for, b...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3248</td>\n",
              "      <td>[The, DSE, all, share, price, index, closed, 2...</td>\n",
              "      <td>[O, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3249</td>\n",
              "      <td>[--, Dhaka, Newsroom, 880-2-506363]</td>\n",
              "      <td>[O, I-ORG, I-ORG, O]</td>\n",
              "      <td>[O, B-ORG, I-ORG, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3250 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 result  \\\n",
              "0     [CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, T...   \n",
              "1                                  [LONDON, 1996-08-30]   \n",
              "2     [West, Indian, all-rounder, Phil, Simmons, too...   \n",
              "3     [Their, stay, on, top, ,, though, ,, may, be, ...   \n",
              "4     [After, bowling, Somerset, out, for, 83, on, t...   \n",
              "...                                                 ...   \n",
              "3245  [But, the, prices, may, move, in, a, close, ra...   \n",
              "3246  [Brokers, said, blue, chips, like, IDLC, ,, Ba...   \n",
              "3247  [They, said, there, was, still, demand, for, b...   \n",
              "3248  [The, DSE, all, share, price, index, closed, 2...   \n",
              "3249                [--, Dhaka, Newsroom, 880-2-506363]   \n",
              "\n",
              "                                                 result  \\\n",
              "0                 [O, O, I-ORG, O, O, O, O, O, O, O, O]   \n",
              "1                                            [I-LOC, O]   \n",
              "2     [I-MISC, I-MISC, O, I-PER, I-PER, O, O, O, O, ...   \n",
              "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, I-ORG,...   \n",
              "4     [O, O, I-ORG, O, O, O, O, O, O, O, O, I-LOC, I...   \n",
              "...                                                 ...   \n",
              "3245   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "3246  [O, O, O, O, O, I-ORG, O, I-ORG, I-ORG, O, I-O...   \n",
              "3247  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "3248  [O, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "3249                               [O, I-ORG, I-ORG, O]   \n",
              "\n",
              "                                                 result  \n",
              "0                 [O, O, B-PER, O, O, O, O, O, O, O, O]  \n",
              "1                                            [B-LOC, O]  \n",
              "2     [B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, ...  \n",
              "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...  \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC...  \n",
              "...                                                 ...  \n",
              "3245   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
              "3246  [O, O, O, O, O, B-ORG, O, B-LOC, O, O, B-PER, ...  \n",
              "3247  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "3248  [O, B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O...  \n",
              "3249                               [O, B-ORG, I-ORG, O]  \n",
              "\n",
              "[3250 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wd4z2k-yDB5",
        "colab_type": "text"
      },
      "source": [
        "### Bert with poolingLayer -2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTBYOs2zyDB5",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb9e9e4e-7624-4922-d3b7-1cc49e5b23ed"
      },
      "source": [
        "bert_annotator.setPoolingLayer(-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_EMBEDDINGS_abf30dcdf344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWHcO4YfyDB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    bert_annotator,\n",
        "    nerTagger\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8iHLdogyDCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ner_model_v2 = pipeline.fit(training_data.limit(1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxdNWrsNyDCF",
        "colab_type": "code",
        "colab": {},
        "outputId": "c2ed35a6-812b-400e-ee17-17178593a154"
      },
      "source": [
        "predictions_v2 = ner_model_v2.transform(test_data.limit(10))\n",
        "\n",
        "predictions_v2.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|I-ORG       |I-ORG     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |I-LOC       |I-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |I-MISC      |I-ORG     |\n",
            "|Indian        |I-MISC      |I-ORG     |\n",
            "|all-rounder   |O           |I-PER     |\n",
            "|Phil          |I-PER       |I-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88j2HqOSyDCK",
        "colab_type": "text"
      },
      "source": [
        "### with Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgM_52NfyDCL",
        "colab_type": "code",
        "colab": {},
        "outputId": "84e9a69c-ff91-4b2d-ca22-8c1c5595fc8d"
      },
      "source": [
        "glove = WordEmbeddingsModel().pretrained() \\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        " .setOutputCol(\"glove\")\\\n",
        " .setCaseSensitive(False)\n",
        "\n",
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "\n",
        "test_data = glove.transform(test_data.limit(1000))\n",
        "\n",
        "test_data.write.parquet(\"test_withGloveEmbeds.parquet\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmYjNXM9yDCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nerTagger.setInputCols([\"sentence\", \"token\", \"glove\"])\n",
        "nerTagger.setTestDataset(\"test_withGloveEmbeds.parquet\")\n",
        "\n",
        "glove_pipeline = Pipeline(\n",
        "    stages = [\n",
        "    glove,\n",
        "    nerTagger\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJZv-XI8yDCS",
        "colab_type": "code",
        "colab": {},
        "outputId": "5340b325-f16d-470a-aabc-f3a60ea48d98"
      },
      "source": [
        "%%time\n",
        "\n",
        "ner_model_v3 = glove_pipeline.fit(training_data.limit(1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26.8 ms, sys: 7.29 ms, total: 34.1 ms\n",
            "Wall time: 17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrwWeJWzyDCX",
        "colab_type": "code",
        "colab": {},
        "outputId": "fdf60dd6-eee0-41a2-8100-35cb5b590837"
      },
      "source": [
        "predictions_v3 = ner_model_v3.transform(test_data.limit(10))\n",
        "\n",
        "# test_data.sample(False,0.1,0)\n",
        "\n",
        "predictions_v3.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |I-MISC    |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|I-ORG       |I-ORG     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |I-LOC       |I-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |I-MISC      |O         |\n",
            "|Indian        |I-MISC      |O         |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |I-PER       |I-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qR673a_yDCd",
        "colab_type": "code",
        "colab": {},
        "outputId": "77525778-70b9-48c7-cbc7-0ecffece5fbb"
      },
      "source": [
        "np.array (predictions.select('token.result').take(1))[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CRICKET', '-', 'LEICESTERSHIRE', 'TAKE', 'OVER', 'AT', 'TOP',\n",
              "       'AFTER', 'INNINGS', 'VICTORY', '.'], dtype='<U14')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGtUrGKuyDCg",
        "colab_type": "code",
        "colab": {},
        "outputId": "c6946872-7aca-4dc4-a096-c07de9f7fea2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "tokens = np.array (predictions.select('token.result').take(1))[0][0]\n",
        "ground = np.array (predictions.select('label.result').take(1))[0][0]\n",
        "label_bert_0 = np.array (predictions.select('ner.result').take(1))[0][0]\n",
        "label_bert_2 = np.array (predictions_v2.select('ner.result').take(1))[0][0]\n",
        "label_glove = np.array (predictions_v3.select('ner.result').take(1))[0][0]\n",
        "\n",
        "pd.DataFrame({'token':tokens,\n",
        "              'ground':ground,\n",
        "              'label_bert_0':label_bert_0,\n",
        "              'label_bert_2':label_bert_2,\n",
        "              'label_glove':label_glove})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>ground</th>\n",
              "      <th>label_bert_0</th>\n",
              "      <th>label_bert_2</th>\n",
              "      <th>label_glove</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>CRICKET</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-MISC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>LEICESTERSHIRE</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>O</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>TAKE</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>OVER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>AT</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>TOP</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>AFTER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>INNINGS</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>VICTORY</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             token ground label_bert_0 label_bert_2 label_glove\n",
              "0          CRICKET      O            O            O      I-MISC\n",
              "1                -      O            O            O           O\n",
              "2   LEICESTERSHIRE  I-ORG            O        I-ORG       I-ORG\n",
              "3             TAKE      O            O            O           O\n",
              "4             OVER      O            O            O           O\n",
              "5               AT      O            O            O           O\n",
              "6              TOP      O            O            O           O\n",
              "7            AFTER      O            O            O           O\n",
              "8          INNINGS      O            O            O           O\n",
              "9          VICTORY      O            O            O           O\n",
              "10               .      O            O            O           O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9-sfND1yDCj",
        "colab_type": "text"
      },
      "source": [
        "### Saving the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fiMY_OuyDCk",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7661627-7550-4204-81c6-503eb300da8d"
      },
      "source": [
        "ner_model_v3.stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WORD_EMBEDDINGS_MODEL_48cffc8b9a76, NerDLModel_9f1a235716e7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNR13ruRyDCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ner_model_v3.stages[1].write().overwrite().save('NER_bert_20200219')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCfzzBMwyDCt",
        "colab_type": "text"
      },
      "source": [
        "## Prediction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO9rbei5yDCu",
        "colab_type": "code",
        "colab": {},
        "outputId": "1e80d798-f234-441e-d881-c2fce77ebe11"
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "bert = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        " .setOutputCol(\"bert\")\\\n",
        " .setCaseSensitive(False)\n",
        "\n",
        "loaded_ner_model = NerDLModel.load(\"NER_bert_20200219\")\\\n",
        " .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        " .setOutputCol(\"ner\")\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_span\")\n",
        "\n",
        "ner_prediction_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        bert,\n",
        "        loaded_ner_model,\n",
        "        converter])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.2 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDTW6Mn1yDCy",
        "colab_type": "code",
        "colab": {},
        "outputId": "efbe7bfe-2576-4b5b-9592-dccb3ad58c28"
      },
      "source": [
        "empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "empty_data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+\n",
            "|text|\n",
            "+----+\n",
            "|    |\n",
            "+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M2TnsP3yDC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_model = ner_prediction_pipeline.fit(empty_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz7XAbGGyDC6",
        "colab_type": "code",
        "colab": {},
        "outputId": "497c8bb3-e0aa-414b-95fe-8280f91889d5"
      },
      "source": [
        "text = \"Peter Parker is a nice guy and lives in New York.\"\n",
        "sample_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "sample_data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Peter Parker is a...|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnvN5SH6yDDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "preds = prediction_model.transform(sample_data)\n",
        "\n",
        "preds.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnAstbiCyDDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds.select('ner_span.result').take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLhc1O0wyDDK",
        "colab_type": "code",
        "colab": {},
        "outputId": "dd75d7e7-e0ea-4240-8d61-317a408ea838"
      },
      "source": [
        "\n",
        "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
        ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|chunk|entity|\n",
            "+-----+------+\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWN1r_VpyDDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "loaded_ner_model = NerDLModel.load(\"NER_bert_20200219\")\\\n",
        " .setInputCols([\"sentence\", \"token\", \"glove\"])\\\n",
        " .setOutputCol(\"ner\")\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_span\")\n",
        "\n",
        "glove_ner_prediction_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        glove,\n",
        "        loaded_ner_model,\n",
        "        converter])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSadthtAyDDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_prediction_model = glove_ner_prediction_pipeline.fit(empty_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkBpWTUwyDDY",
        "colab_type": "code",
        "colab": {},
        "outputId": "03dba0b4-748b-427f-8b18-a3e473008b5a"
      },
      "source": [
        "\n",
        "preds = glove_prediction_model.transform(sample_data)\n",
        "\n",
        "preds.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|               glove|                 ner|            ner_span|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter Parker is a...|[[document, 0, 48...|[[document, 0, 48...|[[token, 0, 4, Pe...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 0, 11, P...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXuk9Vw-yDDb",
        "colab_type": "code",
        "colab": {},
        "outputId": "e0025a3f-1295-4b13-d339-00870a93643a"
      },
      "source": [
        "\n",
        "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
        ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|chunk       |entity|\n",
            "+------------+------+\n",
            "|Peter Parker|PER   |\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d041juj5yDDj",
        "colab_type": "text"
      },
      "source": [
        "### Pretrained Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CG-y-nlyDDj",
        "colab_type": "code",
        "colab": {},
        "outputId": "e1dd87f5-3dbd-4938-cd42-baf0cf9b9276"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "pretrained_pipeline = PretrainedPipeline('recognize_entities_dl', lang='en')\n",
        "\n",
        "#onto_recognize_entities_sm\n",
        "#explain_document_dl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 159 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZtVXgSSyDDn",
        "colab_type": "code",
        "colab": {},
        "outputId": "b074ffbe-5f54-4f8e-d9c7-b1ec3d7669d1"
      },
      "source": [
        "text = \"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\n",
        "\n",
        "result = pretrained_pipeline.annotate(text)\n",
        "\n",
        "list(zip(result['token'], result['ner']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'O'),\n",
              " ('Mona', 'I-PER'),\n",
              " ('Lisa', 'I-PER'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('16th', 'O'),\n",
              " ('century', 'O'),\n",
              " ('oil', 'O'),\n",
              " ('painting', 'O'),\n",
              " ('created', 'O'),\n",
              " ('by', 'O'),\n",
              " ('Leonardo', 'I-PER'),\n",
              " ('.', 'O'),\n",
              " (\"It's\", 'I-ORG'),\n",
              " ('held', 'O'),\n",
              " ('at', 'O'),\n",
              " ('the', 'O'),\n",
              " ('Louvre', 'I-LOC'),\n",
              " ('in', 'O'),\n",
              " ('Paris', 'I-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhg8jdoUyDDp",
        "colab_type": "code",
        "colab": {},
        "outputId": "54fa132a-69c7-4e97-934e-274c557bd117"
      },
      "source": [
        "pretrained_pipeline2 = PretrainedPipeline('explain_document_dl', lang='en')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_dl download started this may take some time.\n",
            "Approx size to download 168.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTfKYzjdyDDv",
        "colab_type": "code",
        "colab": {},
        "outputId": "d2bbc044-ff44-4a12-d043-640c3048b2e6"
      },
      "source": [
        "text = \"The Mona Lisa is a 16th centry oil painting created by Leonrdo. It's held at the Louvre in Paris.\"\n",
        "\n",
        "result2 = pretrained_pipeline2.annotate(text)\n",
        "\n",
        "result2\n",
        "list(zip(result2['token'],  result2['checked'], result2['pos'], result2['ner'],  result2['lemma'],  result2['stem']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'The', 'DT', 'O', 'The', 'the'),\n",
              " ('Mona', 'Mona', 'NNP', 'I-PER', 'Mona', 'mona'),\n",
              " ('Lisa', 'Lisa', 'NNP', 'I-PER', 'Lisa', 'lisa'),\n",
              " ('is', 'is', 'VBZ', 'O', 'be', 'i'),\n",
              " ('a', 'a', 'DT', 'O', 'a', 'a'),\n",
              " ('16th', '6th', 'CD', 'O', '6th', '6th'),\n",
              " ('centry', 'centry', 'NN', 'O', 'centry', 'centri'),\n",
              " ('oil', 'oil', 'NN', 'O', 'oil', 'oil'),\n",
              " ('painting', 'painting', 'NN', 'O', 'painting', 'paint'),\n",
              " ('created', 'created', 'VBN', 'O', 'create', 'creat'),\n",
              " ('by', 'by', 'IN', 'O', 'by', 'by'),\n",
              " ('Leonrdo', 'Leonardo', 'NNP', 'I-ORG', 'Leonardo', 'leonardo'),\n",
              " ('.', '.', '.', 'O', '.', '.'),\n",
              " (\"It's\", 'Itys', 'NNP', 'I-ORG', 'Itys', 'iti'),\n",
              " ('held', 'held', 'VBD', 'O', 'hold', 'held'),\n",
              " ('at', 'at', 'IN', 'O', 'at', 'at'),\n",
              " ('the', 'the', 'DT', 'O', 'the', 'the'),\n",
              " ('Louvre', 'Louvre', 'NNP', 'I-LOC', 'Louvre', 'louvr'),\n",
              " ('in', 'in', 'IN', 'O', 'in', 'in'),\n",
              " ('Paris', 'Paris', 'NNP', 'I-LOC', 'Paris', 'pari'),\n",
              " ('.', '.', '.', 'O', '.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ2rSujZyDDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx= pretrained_pipeline2.fullAnnotate(text)\n",
        "\n",
        "[(n.result, n.metadata['entity']) for n in xx['ner_span']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLefQZkeyDD1",
        "colab_type": "text"
      },
      "source": [
        "## Using your own custom Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpeU7Qq8yDD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_embeddings = WordEmbeddings()\\\n",
        "  .setInputCols([\"sentence\", \"token\"])\\\n",
        "  .setOutputCol(\"glove\")\\\n",
        "  .setStoragePath('/Users/vkocaman/cache_pretrained/PubMed-shuffle-win-2.bin', \"BINARY\")\\\n",
        ".setDimension(200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCMVX81OyDD3",
        "colab_type": "code",
        "colab": {},
        "outputId": "f064f358-e58a-4a26-8f0c-5cb4b052d0e1"
      },
      "source": [
        "custom_embeddings.fit(training_data.limit(10)).transform(training_data.limit(10)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|               glove|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDbVBLK8yDD7",
        "colab_type": "text"
      },
      "source": [
        "## creating your own CoNLL dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYzJSHByyDD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "def get_ann_pipeline ():\n",
        "    \n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"text\")\\\n",
        "        .setOutputCol('document')\n",
        "\n",
        "    sentence = SentenceDetector()\\\n",
        "        .setInputCols(['document'])\\\n",
        "        .setOutputCol('sentence')\\\n",
        "        .setCustomBounds(['\\n'])\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"sentence\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    pos = PerceptronModel.pretrained() \\\n",
        "              .setInputCols([\"sentence\", \"token\"]) \\\n",
        "              .setOutputCol(\"pos\")\n",
        "    \n",
        "    embeddings = WordEmbeddingsModel.pretrained()\\\n",
        "          .setInputCols([\"sentence\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "\n",
        "    ner_model = NerDLModel.pretrained() \\\n",
        "          .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "    ner_pipeline = Pipeline(\n",
        "        stages = [\n",
        "            document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            pos,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "    ner_pipelineFit = ner_pipeline.fit(empty_data)\n",
        "\n",
        "    ner_lp_pipeline = LightPipeline(ner_pipelineFit)\n",
        "\n",
        "    print (\"Spark NLP NER lightpipeline is created\")\n",
        "\n",
        "    return ner_lp_pipeline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU6oTtWUyDD-",
        "colab_type": "code",
        "colab": {},
        "outputId": "aa489fce-b25f-4396-ab4a-5524bbbbc2e4"
      },
      "source": [
        "conll_pipeline = get_ann_pipeline ()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 4.3 MB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "ner_dl download started this may take some time.\n",
            "Approximate size to download 13.5 MB\n",
            "[OK!]\n",
            "Spark NLP NER lightpipeline is created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTGAPGohyDEG",
        "colab_type": "code",
        "colab": {},
        "outputId": "8faa2bb0-0d72-467d-f6b9-3c3fc057acd3"
      },
      "source": [
        "parsed = conll_pipeline.annotate (\"Peter Parker is a nice guy and lives in New York.\")\n",
        "parsed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['Peter Parker is a nice guy and lives in New York.'],\n",
              " 'ner_chunk': ['Peter Parker', 'New York'],\n",
              " 'pos': ['NNP',\n",
              "  'NNP',\n",
              "  'VBZ',\n",
              "  'DT',\n",
              "  'JJ',\n",
              "  'NN',\n",
              "  'CC',\n",
              "  'NNS',\n",
              "  'IN',\n",
              "  'NNP',\n",
              "  'NNP',\n",
              "  '.'],\n",
              " 'token': ['Peter',\n",
              "  'Parker',\n",
              "  'is',\n",
              "  'a',\n",
              "  'nice',\n",
              "  'guy',\n",
              "  'and',\n",
              "  'lives',\n",
              "  'in',\n",
              "  'New',\n",
              "  'York',\n",
              "  '.'],\n",
              " 'ner': ['I-PER',\n",
              "  'I-PER',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'I-LOC',\n",
              "  'I-LOC',\n",
              "  'O'],\n",
              " 'embeddings': ['Peter',\n",
              "  'Parker',\n",
              "  'is',\n",
              "  'a',\n",
              "  'nice',\n",
              "  'guy',\n",
              "  'and',\n",
              "  'lives',\n",
              "  'in',\n",
              "  'New',\n",
              "  'York',\n",
              "  '.'],\n",
              " 'sentence': ['Peter Parker is a nice guy and lives in New York.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYJ8tLfdyDEI",
        "colab_type": "code",
        "colab": {},
        "outputId": "8851e564-a678-42ba-8e9e-6aea6b8baae8"
      },
      "source": [
        "conll_lines=''\n",
        "\n",
        "for token, pos, ner in zip(parsed['token'],parsed['pos'],parsed['ner']):\n",
        "\n",
        "    conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, ner)\n",
        "\n",
        "\n",
        "print(conll_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peter NNP NNP I-PER\n",
            "Parker NNP NNP I-PER\n",
            "is VBZ VBZ O\n",
            "a DT DT O\n",
            "nice JJ JJ O\n",
            "guy NN NN O\n",
            "and CC CC O\n",
            "lives NNS NNS O\n",
            "in IN IN O\n",
            "New NNP NNP I-LOC\n",
            "York NNP NNP I-LOC\n",
            ". . . O\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dKZ39yqyDEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
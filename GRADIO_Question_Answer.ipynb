{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRADIO: Question Answer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdnTLRG-_VUR",
        "colab_type": "text"
      },
      "source": [
        "# Question Answer Model\n",
        "\n",
        "In this notebook, we use multiple inputs for a question answer model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuWz2eII4N0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "a6f77b23-736d-4728-8aee-7e43c0ca36cc"
      },
      "source": [
        "!git clone https://github.com/kamalkraj/BERT-SQuAD.git\n",
        "!pip install -q -r \"BERT-SQuAD/requirements.txt\"\n",
        "!pip install -q gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BERT-SQuAD'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 26 (delta 4), reused 16 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n",
            "\u001b[K     |████████████████████████████████| 143kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 33.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7MB 54.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 962kB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn066ECB5p14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "94151272-61e2-45b9-815b-0469446fe7d9"
      },
      "source": [
        "import gradio as gr\n",
        "import sys\n",
        "sys.path.append(\"BERT-SQuAD\")\n",
        "from bert import QA\n",
        "model = QA('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "\n",
        "def qa_func(context, question):\n",
        "    return model.predict(context, question)[\"answer\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name 'bert-large-uncased-whole-word-masking-finetuned-squad/bert_config.json' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'bert-large-uncased-whole-word-masking-finetuned-squad/bert_config.json' was a path or url but couldn't find any file associated to this path or url.\n",
            "The pre-trained model you are loading is an uncased model but you have set `do_lower_case` to False. We are setting `do_lower_case=True` for you but you may want to check this behavior.\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 589044.74B/s]\n",
            "100%|██████████| 443/443 [00:00<00:00, 100079.54B/s]\n",
            "100%|██████████| 1340675298/1340675298 [00:57<00:00, 23435260.82B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDyjoZfg6pRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "54d52034-f750-485a-ed20-76ec6413e573"
      },
      "source": [
        "gr.Interface(qa_func, \n",
        "    [\n",
        "        gr.inputs.Textbox(lines=7, label=\"Context\"), \n",
        "        gr.inputs.Textbox(label=\"Question\"), \n",
        "    ], \n",
        "    gr.outputs.Textbox(label=\"Answer\"),\n",
        "    title=\"Question Answer\",\n",
        "    description=\"BERT-SQuAD is a question answering model that takes 2 inputs: a paragraph that provides context and a question that should be answered. Takes around 6s to run.\").launch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on External URL: https://54373.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://54373.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ff1d0d4ada0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.networking.serve_files_in_background.<locals>.HTTPServer at 0x7ff1d19d25c0>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://54373.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZnoOhLImRH8",
        "colab_type": "text"
      },
      "source": [
        "#### Your model is now live on the gradio.app link shown above. Go ahead and open that in a new tab!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFi225G1mdah",
        "colab_type": "text"
      },
      "source": [
        "Please contact us [here](mailto:team@gradio.app) if you have any questions, or [open an issue](https://github.com/gradio-app/gradio-UI/issues/new/choose) at our github repo."
      ]
    }
  ]
}